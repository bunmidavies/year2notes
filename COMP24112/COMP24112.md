# "Machine Learning"

[[ML chapter summaries]]
[[COMP24112Maths.pdf]]
[[numpy]]


# ~ weeks
***
### week 1 - ==ML basics==
*intro + background info*
- [[what is machine learning + history of machine learning]]
- [[machine learning strategies (data + model strategy)]]
- [[ML optimisation]]
- [[typical machine learning tasks]]

*the machine learning pipeline*
- [[machine learning pipeline]]
- [[ml pipeline example - wine classification]]

*supervised learning, unsupervised learning and reinforcement learning*
- [[supervised learning]]
- [[unsupervised learning]]
- [[reinforcement learning]]

*classification vs regression*
- [[classification]]
- [[regression]]

### week 2 - ==k-Nearest Neighbours==
*intro to instance based learning, and kNN*
- [[k nearest neighbour (k-NN)]]
- [[instance based learning]]
- [[distance measuring for k-NN]]

[[effect of training samples for k-NN]]
[[effect of neighbour number for k-NN]]
[[neighbour searching algorithms]]

### week 3 - ==machine learning experiments==
*chapter A*
[[classification performance measures]]
[[regression performance measures]]

*chapter B*
[[sample error vs true error]]
[[limited data issues]]
[[data splitting methods]]
[[machine learning experiment]]
[[hyper-parameter selection]]
[[bias-variance decomposition]] - overfitting and underfitting

*chapter C*
[[model comparison]]
[[confidence interval]]
[[z-tests for hypotheses]]

### week 4 - ==typical ML models==
*chapter A*
recap of data + model strategy from [[machine learning strategies (data + model strategy)]]
[[probabilistic vs non-probabilistic model]]
[[discriminant function]] 
[[probabilistic inference]]

*chapter B*
[[single-output functions + multi-output functions]]
[[parametric + non-parametric models]]
[[linear models]]
[[hyperplanes in linear functions]]

*chapter C*
[[handling non-linear data patterns]]

### week 5 - ==loss functions==
*chapter A*
- recap of [[machine learning strategies (data + model strategy)]]
- [[non probabilistic regression losses]] + [[overfitting and underfitting]]
- [[probabilistic regression losses]]

*chapter B*
- [[non probabilistic classification losses]]
- [[probabilistic classification losses]]

### week 6 - ==training and optimisation==
*chapter A*
- revision of [[machine learning pipeline]], and the [[optimality condition]]
- [[linear least squares]] and [[regularised least squares]]
- [[normal equations]]

*chapter B*
- applications of [[linear least squares]] / [[regularised least squares]]

*chapter C*
- [[iterative optimisation approaches]]:
	- [[gradient descent]]
	- [[stochastic gradient descent + mini-batch gradient descent]]

### week 7 - ==revision week==
no content this week

### week 8 - ==artificial neural networks==
*chapter A*
- [[artificial neural networks]]

*chapter B*
- [[training neural networks]] (hebbian learning + gradient based)

*chapter C*
- [[backpropagation]]

### week 9 - ==support vector machines==
*chapter A*
- [[support vector machines (SVMs)]]

*chapter B*
- [[SVMs for non-separable patterns]]
- [[SVMs for linear regression]]

*chapter C*
- [[ROC analysis]]
- [[supervised learning]] techniques pros and cons
- [[no free lunch theorem]]

### week 10 - ==clustering==
*chapter A*
- [[clustering]]
- [[cluster distance measures]]

*chapter B*
- [[k-means clustering]]
- [[hierarchical clustering]]

*chapter C*
- [[categories of clustering algorithms]]
- [[cluster validation]]