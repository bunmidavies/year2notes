[[COMP24112]]

### definition
- the concept of attention in deep learning mainly stems from applications within natural language processing, coupled with machine translation - its simply defined as ==memory per unit of time==
- an attention mechanism is essentially embedded in a neural network, to help it make decisions which can be better interpreted - it helps the model focus its 'attention' on specific parts of input data while performing a task